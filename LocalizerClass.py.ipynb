{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "eee170fc-cc2d-4321-b2a3-f4528004232c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "import time\n",
    "import mlflow\n",
    "from contextlib import contextmanager\n",
    "import json\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import re\n",
    "import openai\n",
    "from openai import OpenAI\n",
    "import gspread\n",
    "import random\n",
    "import logging\n",
    "import os\n",
    "from unidecode import unidecode\n",
    "from pathlib import Path\n",
    "import pyspark\n",
    "from pyspark.sql.functions import *\n",
    "from functools import reduce\n",
    "from typing import *\n",
    "import tiktoken\n",
    "\n",
    "#from rouge_score import rouge_scorer\n",
    "#from bert_score import score as bert_score\n",
    "\n",
    "\n",
    "\n",
    "from general_config import *\n",
    "EXPERIMENT_NAME = \"/Users/krista@jamcity.com/centralized_loc_translation_run\"\n",
    "\n",
    "#from config import EXPERIMENT_NAME\n",
    "\n",
    "request_example =  {\"RowFingerprint\":\"\",\n",
    "                    \"Timestamp\":\"\",\n",
    "                    \"SubmitterEmail\":\"\",\n",
    "                    \"DueDate\":\"\",\n",
    "                    'LocType':\"\", \n",
    "                    'Game':\"\", \n",
    "                    'TargetLanguages':\"\", \n",
    "                    \"URL\":\"\",\n",
    "                    \"QAFlag\":\"\"}\n",
    "\n",
    "cfg_example = {\n",
    "    \"input\": {\"required_tabs\": [\"ios\",\"android\"], \"ios_header_rows\": 3, \"android_header_rows\": 3},\n",
    "    \"char_limit_policy\": \"strict\"\n",
    "}\n",
    "aso_cfg_example = {\n",
    "    \"input\": {\"required_tabs\": [\"ios\",\"android\"], \"ios_header_rows\": 3, \"android_header_rows\": 3},\n",
    "    \"char_limit_policy\": \"strict\",\n",
    "    \"output_sheets\":[\"formatted_ios\", \"formatted_android\", \"long_results\"]}\n",
    "\n",
    "class MLTracker:\n",
    "    def __init__(self, request, language=None, experiment_name=EXPERIMENT_NAME):\n",
    "        self.request = request\n",
    "        self.language = language\n",
    "        self.experiment_name = experiment_name\n",
    "        self.run = None\n",
    "        self._events = []\n",
    "\n",
    "    @staticmethod\n",
    "    def _parse_langs(raw_langs: str | None):\n",
    "        if not raw_langs:\n",
    "            return []\n",
    "        parts = [x.strip() for x in raw_langs.replace(\";\", \",\").split(\",\")]\n",
    "        return [x for x in parts if x]\n",
    "\n",
    "    def start(self, nested: bool = False):\n",
    "        mlflow.set_experiment(self.experiment_name)\n",
    "\n",
    "        # Run name: request row id + optional language suffix\n",
    "        base_name = self.request.get(\"Game\")\n",
    "        run_id = self.request.get(\"RowFingerprint\") or self.request.get(\"RequestID\", \"run\")\n",
    "        base_name = f\"{base_name}:{run_id}\"\n",
    "        run_name = f\"{base_name}:{self.language}\" if self.language else base_name\n",
    "\n",
    "        self.run = mlflow.start_run(run_name=run_name, nested=nested)\n",
    "\n",
    "        # Tags (request-level + language-level)\n",
    "        tags = {\n",
    "            \"RowFingerprint\": self.request.get(\"RowFingerprint\",\"\"),\n",
    "            \"LocType\": self.request.get(\"LocType\",\"\"),\n",
    "            \"Game\": self.request.get(\"Game\",\"\"),\n",
    "            \"InputSheetURL\": self.request.get(\"URL\",\"\"),\n",
    "            \"status\": \"RUNNING\",\n",
    "        }\n",
    "        if self.language:\n",
    "            tags[\"Language\"] = self.language\n",
    "        mlflow.set_tags(tags)\n",
    "\n",
    "        # Params\n",
    "        if not self.language:\n",
    "            # parent: log the list of languages once\n",
    "            langs = self._parse_langs(self.request.get(\"TargetLanguages\"))\n",
    "            mlflow.log_params({\n",
    "                \"TargetLanguages\": \",\".join(langs),\n",
    "                \"QAFlag\": str(self.request.get(\"QAFlag\", False)),\n",
    "            })\n",
    "        else:\n",
    "            # child run: log just this language\n",
    "            mlflow.log_param(\"Language\", self.language)\n",
    "\n",
    "        return self.run.info.run_id\n",
    "\n",
    "    def end(self, succeeded: bool, err_text: str | None = None):\n",
    "        mlflow.set_tag(\"status\", \"SUCCEEDED\" if succeeded else \"FAILED\")\n",
    "        if self._events:\n",
    "            mlflow.log_text(\"\\n\".join(self._events), \"logs/events.txt\")\n",
    "        if err_text:\n",
    "            mlflow.log_text(err_text, \"logs/error.txt\")\n",
    "        mlflow.end_run()\n",
    "\n",
    "    def event(self, msg: str):\n",
    "        ts = time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        mlflow.set_tag(\"last_event\", msg)\n",
    "        self._events.append(f\"[{ts}] {msg}\")\n",
    "\n",
    "    def dict(self, obj, path: str):\n",
    "        mlflow.log_dict(obj, path)\n",
    "\n",
    "    def text(self, txt: str, path: str):\n",
    "        mlflow.log_text(txt, path)\n",
    "\n",
    "    def metrics(self, d: dict, step: int | None = None):\n",
    "        mlflow.log_metrics({k: float(v) for k, v in d.items()}, step=step)\n",
    "\n",
    "    def params(self, d: dict):\n",
    "        mlflow.log_params({k: str(v) for k, v in d.items()})\n",
    "\n",
    "    @contextmanager\n",
    "    def step(self, name: str):\n",
    "        start = time.time()\n",
    "        self.event(f\"Step start: {name}\")\n",
    "        try:\n",
    "            yield\n",
    "        finally:\n",
    "            dur = time.time() - start\n",
    "            self.metrics({f\"duration_sec.{name}\": dur})\n",
    "\n",
    "    @contextmanager\n",
    "    def nested(self, name: str, tags: dict | None = None, params: dict | None = None):\n",
    "        # You can still do sub-steps inside a language if you want (e.g., per-batch)\n",
    "        with mlflow.start_run(run_name=name, nested=True):\n",
    "            if tags: mlflow.set_tags(tags)\n",
    "            if params: self.params(params)\n",
    "            yield\n",
    "\n",
    "\n",
    "class LocalizationRun(ABC):\n",
    "    def __init__(self, \n",
    "                 request, \n",
    "                 gsheet_client=None, \n",
    "                 gpt_client=None, \n",
    "                 cfg=None,\n",
    "                 tracker: MLTracker | None = None):\n",
    "        \"\"\"\n",
    "        request: dict with fields like RequestID, LocType, Game, TargetLanguages, etc.\n",
    "        gsheet_client: injected dependency for Google Sheets\n",
    "        gpt_client: injected dependency for GPT API\n",
    "        cfg: loaded YAML/JSON config for this LocType\n",
    "        \"\"\"\n",
    "        self.request = request\n",
    "        self.gc = gsheet_client\n",
    "        self.gpt = gpt_client\n",
    "        self.cfg = cfg or {}\n",
    "        self.artifacts = {}\n",
    "        self.tracker =  MLTracker(request, language=None)\n",
    "        self.lang_trackers = {}\n",
    "        \n",
    "    def run(self):\n",
    "        parent_run_id = self.tracker.start()  # parent request-level run\n",
    "        try:\n",
    "            with self.tracker.step(\"validate_inputs\"):\n",
    "                self.validate_inputs()\n",
    "\n",
    "            with self.tracker.step(\"load_inputs\"):\n",
    "                data = self.load_inputs()\n",
    "                self.tracker.dict({\"preview\": str(data)[:2000]}, \"snapshots/input_preview.json\")\n",
    "\n",
    "            with self.tracker.step(\"preprocess\"):\n",
    "                prepped = self.preprocess(data)\n",
    "                self.tracker.metrics({\"rows.prepped\": len(prepped)})\n",
    "\n",
    "            with self.tracker.step(\"build_prompts\"):\n",
    "                prompts = self.build_prompts(prepped)\n",
    "                self.tracker.metrics({\"prompts.count\": len(prompts)})\n",
    "\n",
    "            # Build per-language trackers (child runs) using request languages\n",
    "            langs = MLTracker._parse_langs(self.request.get(\"TargetLanguages\"))\n",
    "            # TODO:\n",
    "            # This could be remedied by just using self.languages instad of self.request.get(\"TargetLanguages\") and parsing\n",
    "            for lang in langs:\n",
    "                self.lang_trackers[lang] = MLTracker(\n",
    "                    request=self.request,\n",
    "                    language=lang,\n",
    "                    experiment_name=self.tracker.experiment_name  # same experiment\n",
    "                )\n",
    "\n",
    "            outputs = self.translate(prompts)  # tracked per language below\n",
    "\n",
    "            with self.tracker.step(\"postprocess\"):\n",
    "                final_rows = self.postprocess(outputs)\n",
    "                self.tracker.metrics({\"rows.final\": len(final_rows)})\n",
    "\n",
    "            with self.tracker.step(\"write_outputs\"):\n",
    "                self.write_outputs(final_rows)\n",
    "\n",
    "            self.tracker.end(succeeded=True)\n",
    "            return {\"status\": \"SUCCEEDED\", \"run_id\": parent_run_id}\n",
    "        except Exception as e:\n",
    "            self.tracker.end(succeeded=False, err_text=str(e))\n",
    "            raise\n",
    "\n",
    "    # Shared, tracked translate that spins one child run per language\n",
    "    def translate(self, groups):\n",
    "        parent = self.tracker\n",
    "        #batch_size = int(batch_size or self.cfg.get(\"batch_size\", 50))\n",
    "\n",
    "        total_prompt_tokens = 0\n",
    "        total_completion_tokens = 0\n",
    "        results = []\n",
    "\n",
    "        with parent.step(\"translate\"):\n",
    "            # TODO: we actually already have them batched in a preprocessing step\n",
    "            #groups = self._group_prompts_for_translation(prompt_batch) # remove!!!\n",
    "            #groups = self.groups \n",
    "            parent.metrics({\"translate.groups\": len(groups)})\n",
    "\n",
    "            for group_name, prompts in groups.items():\n",
    "                # pick the language tracker matching group_name; fallback to a generic child tracker\n",
    "                lang_tracker = self.lang_trackers.get(group_name) or MLTracker(\n",
    "                    request=self.request,\n",
    "                    language=group_name,\n",
    "                    experiment_name=parent.experiment_name\n",
    "                )\n",
    "                # Start the child run as nested=True\n",
    "                lang_run_id = lang_tracker.start(nested=True)\n",
    "                try:\n",
    "                    lang_total_p = 0\n",
    "                    lang_total_c = 0\n",
    "\n",
    "                    with lang_tracker.step(\"api_batch\"):\n",
    "                        out, usage = self._call_model_batch(prompts)  # subclass hook\n",
    "                        results.append(out)\n",
    "\n",
    "                        lang_total_p = (usage or {}).get(\"prompt_tokens\", 0)\n",
    "                        lang_total_c = (usage or {}).get(\"completion_tokens\", 0)\n",
    "\n",
    "\n",
    "                    # per-language metric\n",
    "                    lang_tracker.metrics({\n",
    "                        \"items.total\": len(prompts),\n",
    "                        \"tokens.prompt.total\": lang_total_p,\n",
    "                        \"tokens.completion.total\": lang_total_c,\n",
    "                    })\n",
    "\n",
    "                    # accumulate into parent\n",
    "                    total_prompt_tokens += lang_total_p\n",
    "                    total_completion_tokens += lang_total_c\n",
    "\n",
    "                    lang_tracker.end(succeeded=True)\n",
    "\n",
    "                    \"\"\"\n",
    "                    ##TODO: We dont need to loop by batch, only by language\n",
    "                    for i in range(0, len(prompts), batch_size):\n",
    "                        batch = prompts[i:i+batch_size]\n",
    "                        with lang_tracker.step(\"api_batch\"):\n",
    "                            out, usage = self._call_model_batch(batch)  # subclass hook\n",
    "                            results.extend(out)\n",
    "\n",
    "                            p = (usage or {}).get(\"prompt_tokens\", 0)\n",
    "                            c = (usage or {}).get(\"completion_tokens\", 0)\n",
    "                            lang_total_p += p\n",
    "                            lang_total_c += c\n",
    "\n",
    "                            lang_tracker.metrics({\n",
    "                                \"items.batch\": len(batch),\n",
    "                                \"tokens.prompt.batch\": p,\n",
    "                                \"tokens.completion.batch\": c,\n",
    "                            })\n",
    "\n",
    "                    # per-language rollup\n",
    "                    lang_tracker.metrics({\n",
    "                        \"items.total\": len(prompts),\n",
    "                        \"tokens.prompt.total\": lang_total_p,\n",
    "                        \"tokens.completion.total\": lang_total_c,\n",
    "                    })\n",
    "                    # accumulate into parent\n",
    "                    total_prompt_tokens += lang_total_p\n",
    "                    total_completion_tokens += lang_total_c\n",
    "\n",
    "                    lang_tracker.end(succeeded=True)\"\"\"\n",
    "\n",
    "                except Exception as e:\n",
    "                    lang_tracker.end(succeeded=False, err_text=str(e))\n",
    "                    raise\n",
    "\n",
    "            # parent rollup\n",
    "            parent.metrics({\n",
    "                \"tokens.prompt.total\": total_prompt_tokens,\n",
    "                \"tokens.completion.total\": total_completion_tokens,\n",
    "            })\n",
    "\n",
    "        return results\n",
    "    \n",
    "    \"\"\"\n",
    "    # Actually TODO: Lets alter this\n",
    "    # Default grouping: by 'lang' key if present\n",
    "    #def _group_prompts_for_translation(self, prompts):\n",
    "\n",
    "        ###REMOVE THIS! It's already prepared before now!!\n",
    "    #    groups = {}\n",
    "    #    for p in prompts:\n",
    "    #        key = p.get(\"lang\", \"default\")\n",
    "    #        groups.setdefault(key, []).append(p)\n",
    "    \"\"\"\n",
    "\n",
    "    @abstractmethod\n",
    "    def _call_model_batch(self, prompt):\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def validate_inputs(self): \n",
    "        pass\n",
    "    \n",
    "    @abstractmethod\n",
    "    def load_inputs(self):\n",
    "        pass\n",
    "    \n",
    "    @abstractmethod\n",
    "    def preprocess(self, data): \n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def build_prompts(self, prepped): \n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def postprocess(self, outputs): \n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def write_outputs(self, post): \n",
    "        pass\n",
    "\n",
    "\n",
    "class ASOLocalizer(LocalizationRun):\n",
    "\n",
    "    def __init__(self, \n",
    "                 request, \n",
    "                 gsheet_client=None, \n",
    "                 gpt_client=None, \n",
    "                 cfg=None, \n",
    "                 tracker: MLTracker | None = None):\n",
    "        super().__init__(request, gsheet_client, gpt_client, cfg, tracker)\n",
    "\n",
    "        # Now subclass-specific initialization\n",
    "        self.required_tabs = self.cfg.get(\"input\", {}).get(\"required_tabs\", [])\n",
    "        self.char_limit_policy = self.cfg.get(\"char_limit_policy\", \"strict\")\n",
    "        # e.g., store header row counts for ios/android\n",
    "        self.ios_header_rows = self.cfg.get(\"input\", {}).get(\"ios_header_rows\", 3)\n",
    "        self.android_header_rows = self.cfg.get(\"input\", {}).get(\"android_header_rows\", 3)\n",
    "        self.sh = None\n",
    "        self.ios_wksht = None\n",
    "        self.android_wksht = None\n",
    "        self.ios_long_df = None\n",
    "        self.ios_wide_df = None\n",
    "        self.android_long_df = None\n",
    "        self.android_wide_df = None\n",
    "\n",
    "\n",
    "    def validate_inputs(self): \n",
    "\n",
    "        # Open url\n",
    "        try:\n",
    "            sh = self.gsheet_client.open_by_url(self.request.get(\"url\"))\n",
    "        except Exception as e:\n",
    "            raise Exception(f\"Invalid spreadsheet URL: {e}\")\n",
    "\n",
    "        wkshts = sh.worksheets()\n",
    "        for i in self.required_tabs:\n",
    "            if i not in [w.title for w in wkshts]:\n",
    "                raise Exception(f\"Required tab '{i}' not found in spreadsheet '{self.request.get('url')}'\")\n",
    "        self.sh = sh\n",
    "\n",
    "        # Validate IOS formatting - if no data, leave the worksheet object as None\n",
    "        ios_data =  self.sh.worksheet('ios').get_all_records()\n",
    "        ios_rows = len(ios_data)\n",
    "        if len(ios_data) >=4:\n",
    "            self.ios_wksht = sh.worksheet('ios')\n",
    "           \n",
    "\n",
    "        #Validate Android Formatting\n",
    "        android_data =  self.sh.worksheet('android').get_all_records()\n",
    "        android_rows = len(android_data)\n",
    "        if len(android_data)>=4:\n",
    "            self.android_wksht = sh.worksheet('android')\n",
    "\n",
    "        return\n",
    "    \n",
    "    #TODO: convert to wide\n",
    "    def _convert_wide_to_long_inputs(self, df, type):\n",
    "\n",
    "        df = spark.createDataFrame(df)\n",
    "        if type == \"ios\":\n",
    "            return\n",
    "        \n",
    "        if type == \"android\":\n",
    "\n",
    "            return\n",
    "        \n",
    "        return\n",
    "\n",
    "    def load_inputs(self):\n",
    "        if self.ios_wksht:\n",
    "            ios_data = self.ios_wksht.get_all_records()\n",
    "            ios_headers, ios_vals = ios_data[0:2], ios_data[3:]\n",
    "            self.ios_wide_df = pd.DataFrame(ios_data)\n",
    "            #TODO: \n",
    "            self.ios_long_df = self._convert_wide_to_long_inputs(self.ios_wide_df,'ios')\n",
    "        if self.android_wksht:\n",
    "            self.android_wide_df = pd.DataFrame(self.ios_wksht.get_all_records())\n",
    "            self.android_long_df = self._convert_wide_to_long_inputs(self.android_wide_df,'android')\n",
    "\n",
    "        # Join the two dataframes \n",
    "        self.joined_long = pd.concat([self.ios_long_df, self.android_long_df], axis=0)\n",
    "\n",
    "        return\n",
    "    def _group_prompts_for_translation(self, prompts):\n",
    "        #[{'lang':\"\",\"prompts\":[]}]\n",
    "        return groups\n",
    " \n",
    "    def preprocess(self, data): \n",
    "        #prepped = [] # List of data objects to be translated, by language\n",
    "        #for i in range(len(self.ios_long_df))\n",
    "        return prepped\n",
    "    \n",
    "    def build_prompts(self, prepped): \n",
    "        # ASO Guidelines\n",
    "        # Language Specific\n",
    "        # Game Specific \n",
    "        # Add dump of prepped for each language\n",
    "        \n",
    "        prompts = []\n",
    "\n",
    "        return\n",
    "\n",
    "    \"\"\"\n",
    "    # ---- the helper you asked about ----\n",
    "    def _translate_with_tracking(self, prompt_batch, batch_size: int = 50):\n",
    "        tr = self.tracker\n",
    "\n",
    "        total_prompt_tokens = 0\n",
    "        total_completion_tokens = 0\n",
    "        total_batches = math.ceil(len(prompt_batch)/batch_size)\n",
    "        results = []\n",
    "\n",
    "        with tr.step(\"translate\"):  # overall translate timing\n",
    "            # Example: group by language (if prompt objects carry a 'lang' key)\n",
    "            groups = self._group_prompts_by_lang(prompt_batch)  # dict[lang] = list[prompts]\n",
    "\n",
    "            for lang, prompts in groups.items():\n",
    "                with tr.nested(f\"translate:{lang}\", tags={\"lang\": lang}, params={\"count\": len(prompts)}):\n",
    "                    for b_i in range(0, len(prompts), batch_size):\n",
    "                        batch = prompts[b_i:b_i+batch_size]\n",
    "                        with tr.step(f\"api_batch\"):\n",
    "                            # --- call your GPT client (returns outputs + usage) ---\n",
    "                            out, usage = self.gpt.translate_batch(batch)\n",
    "                            results.extend(out)\n",
    "\n",
    "                            # usage is expected like: {\"prompt_tokens\": int, \"completion_tokens\": int}\n",
    "                            p = usage.get(\"prompt_tokens\", 0)\n",
    "                            c = usage.get(\"completion_tokens\", 0)\n",
    "                            total_prompt_tokens += p\n",
    "                            total_completion_tokens += c\n",
    "\n",
    "                            # log batch-level metrics\n",
    "                            tr.metrics({\n",
    "                                \"tokens.prompt.batch\": p,\n",
    "                                \"tokens.completion.batch\": c,\n",
    "                                \"items.batch\": len(batch),\n",
    "                            })\n",
    "\n",
    "                    # helpful per-lang rollup\n",
    "                    tr.metrics({\n",
    "                        f\"items.per_lang.{lang}\": len(prompts),\n",
    "                    })\n",
    "\n",
    "        # global counters\n",
    "        tr.metrics({\n",
    "            \"tokens.prompt.total\": total_prompt_tokens,\n",
    "            \"tokens.completion.total\": total_completion_tokens,\n",
    "            \"batches.total\": total_batches,\n",
    "            \"items.total\": len(prompt_batch),\n",
    "        })\n",
    "\n",
    "        # (Optional) save raw model responses as an artifact\n",
    "        # tr.dict(results, \"snapshots/model_outputs.json\")\n",
    "\n",
    "        return results\n",
    "\n",
    "    def _group_prompts_by_lang(self, prompts):\n",
    "        # e.g., each prompt is {\"lang\": \"es_LA\", \"payload\": {...}}\n",
    "        groups = {}\n",
    "        for p in prompts:\n",
    "            lang = p.get(\"lang\", \"unknown\")\n",
    "            groups.setdefault(lang, []).append(p)\n",
    "        return groups\n",
    "    \"\"\"\n",
    "    def postprocess(self, outputs): return\n",
    "\n",
    "    def write_outputs(self, post): return\n",
    "\n",
    "class MarketingLocalizer(LocalizationRun):\n",
    "\n",
    "    def __init__(self, \n",
    "                 request, \n",
    "                 gsheet_client=None, \n",
    "                 gpt_client=None, \n",
    "                 cfg=None, \n",
    "                 tracker: MLTracker | None = None):\n",
    "         \n",
    "        super().__init__(request, gsheet_client, gpt_client, cfg, tracker)\n",
    "\n",
    "        # Now subclass-specific initialization\n",
    "        self.required_tabs = self.cfg.get(\"input\", {}).get(\"required_tabs\", [])\n",
    "        #self.input_headers = []\n",
    "        #self.char_limit_policy = self.cfg.get(\"char_limit_policy\", \"\")\n",
    "\n",
    "\n",
    "    def validate_inputs(self): \n",
    "        return\n",
    "    \n",
    "    def load_inputs(self):\n",
    "        return\n",
    " \n",
    "    def preprocess(self, data): \n",
    "        return\n",
    "    \n",
    "    def build_prompts(self, prepped): return\n",
    "\n",
    "\n",
    "    def translate(self, prompt_batch): return\n",
    "\n",
    "\n",
    "    def postprocess(self, outputs): return\n",
    "\n",
    "    def write_outputs(self, post): return\n",
    "\n",
    "class CSLocalizer(LocalizationRun):\n",
    "\n",
    "    def __init__(self, \n",
    "                 request, \n",
    "                 gsheet_client=None, \n",
    "                 gpt_client=None, \n",
    "                 cfg=None, \n",
    "                 tracker: MLTracker | None = None):\n",
    "        super().__init__(request, gsheet_client, gpt_client, cfg, tracker)\n",
    "    def validate_inputs(self): \n",
    "        return\n",
    "    \n",
    "    def load_inputs(self):\n",
    "        return\n",
    " \n",
    "    def preprocess(self, data): \n",
    "        return\n",
    "    \n",
    "    def build_prompts(self, prepped): return\n",
    "\n",
    "\n",
    "    def translate(self, prompt_batch): return\n",
    "\n",
    "\n",
    "    def postprocess(self, outputs): return\n",
    "\n",
    "    def write_outputs(self, post): return\n",
    "\n",
    "\n",
    "##############################################\n",
    "\n",
    "from InGame_Config import * \n",
    "\n",
    "class InGameLocalizer(LocalizationRun):\n",
    "\n",
    "    def __init__(self, \n",
    "                 request, \n",
    "                 gsheet_client=None, \n",
    "                 gpt_client=None, \n",
    "                 cfg=None, \n",
    "                 tracker: MLTracker | None = None):\n",
    "         \n",
    "        super().__init__(request, gsheet_client, gpt_client, cfg, tracker)\n",
    "\n",
    "        self.required_tabs = self.cfg.get(\"input\", {}).get(\"required_tabs\", [])\n",
    "        self.char_limit_policy = self.cfg.get(\"char_limit_policy\", \"\")\n",
    "\n",
    "    def validate_inputs(self):\n",
    "        \n",
    "        # Open Sheet\n",
    "        try:\n",
    "            self.sh = self.gsheet_client.open_by_url(self.request.get)\n",
    "        except Exception as e:\n",
    "            raise Exception(f\"Error opening google sheet: {e}\")\n",
    "        \n",
    "        #Open Tab\n",
    "        try:\n",
    "            self.wksht = self.sh.worksheet(\"input\")\n",
    "        except Exception as e:\n",
    "            raise Exception(f\"Error opening input tab: {e}\")\n",
    "        \n",
    "        # Check if all required tabs are present\n",
    "        wkshts = self.sh.worksheets()\n",
    "        for tab in self.required_tabs:\n",
    "            if tab not in [wksht.title for wksht in wkshts]:\n",
    "                self.sh.add_worksheet(tab)\n",
    "                # with expected header row\n",
    "    \n",
    "        return\n",
    "    \n",
    "    def load_inputs(self):\n",
    "\n",
    "        data = self.wksht.get_all_values()\n",
    "        self.input_headers = data.pop(0)\n",
    "        self.data = data\n",
    "        self.df = pd.DataFrame(data, columns=self.input_headers) #pandas DF\n",
    "\n",
    "        return self.data\n",
    " \n",
    "    def preprocess(self, data:List[str])->str: \n",
    "\n",
    "        ## Convert data to slug....\n",
    "        prepped = json.dumps(self.df.to_dict(orient='records'))\n",
    "\n",
    "        return prepped\n",
    "    \n",
    "    def _get_game_context(self):\n",
    "\n",
    "        \"\"\" Helper function to get relevant context for in game localization for particular game \"\"\"\n",
    "        game = self.request.get('Game')\n",
    "        self.game = game\n",
    "        self.lang_specific_guidelines = GENRAL_LANG_SPECIFIC_GUIDELINES\n",
    "        self.general_game_specific_guidelines = GENERAL_LANG_SPECIFIC_GUIDELINES\n",
    "\n",
    "        # Specifics for games\n",
    "        if game == \"Panda Pop\":\n",
    "            self.game_description = self.general_game_specific_guidelines[game]\n",
    "            self.lang_map = PP_LANG_MAP\n",
    "        \n",
    "            # game specific prompt inputs \n",
    "            self.ex_input = PP_EX_INPUT\n",
    "            self.context_infer = PP_CONTEXT_INFER\n",
    "            self.token_infer = PP_TOKEN_INFER\n",
    "        \n",
    "        if game == \"Cookie Jam Blast\":\n",
    "            self.game_description = self.general_game_specific_guidelines[game]\n",
    "            self.lang_map = CJB_LANG_MAP\n",
    "\n",
    "            # game specific prompt inputs \n",
    "            self.ex_input = CJB_EX_INPUT\n",
    "            self.context_infer = CJB_CONTEXT_INFER\n",
    "            self.token_infer = CJB_TOKEN_INFER\n",
    "            \n",
    "        if game == \"Genies & Gems\":\n",
    "            self.game_description = self.general_game_specific_guidelines[game]\n",
    "            self.lang_map = GG_LANG_MAP\n",
    "    \n",
    "            # game specific prompt inputs \n",
    "            self.ex_input = GG_EX_INPUT\n",
    "            self.context_infer = GG_CONTEXT_INFER\n",
    "            self.token_infer = GG_TOKEN_INFER\n",
    "\n",
    "        self.languages = list(self.lang_map.keys())\n",
    "        self.lang_cds = list(self.lang_map.vaues())\n",
    "\n",
    "    def _generate_prompt_helper(self, \n",
    "                                language:str, \n",
    "                                game:str, \n",
    "                                prepped:str)->List[Dict[str, Any]]:\n",
    "\n",
    "        base = f\"\"\" \n",
    "            You are a professional game localizer translating for a popular mobile puzzle game called {self.game} by Jam City which is described as:\n",
    "            {self.game_description}\n",
    "            Please translate the in-game phrases provided below from English into {language}.\n",
    "                •   Keep the translations natural, playful, and appropriate for a casual mobile gaming tone.\n",
    "                •   Avoid overly formal or mechanical language.\n",
    "                •   There is no strict character limit, but translations should not be egregiously longer than the original English text.\n",
    "                •   {self.token_infer}\n",
    "                •   {self.context_infer}\n",
    "            If present, use the context to guide tone, word choice, or brevity — especially when the English phrase is vague or could be interpreted multiple ways.\n",
    "            Example Inputs as a json string:\n",
    "            json\n",
    "                {self.ex_input}\n",
    "            \n",
    "            \"\"\"\n",
    "        base += f\"\"\"\n",
    "            You MUST follow these language specific guidelines:\n",
    "            {self.lang_specfic_guidelines[language]} \n",
    "            \"\"\"\n",
    "\n",
    "        lang_cd = self.lang_map[language]\n",
    "    \n",
    "        base += f\"\"\"\n",
    "            Respond in **JSON format**, one object per row:\n",
    "            json\n",
    "            [\n",
    "            {{ \"token\": \"token_name_1\", \"{lang_cd}\": \"translated phrase 1\" }},\n",
    "            {{ \"token\": \"token_name_2\", \"{lang_cd}\": \"translated phrase 2\" }},\n",
    "            ...\n",
    "            ]\\n\\n\n",
    "            \"\"\"\n",
    "    \n",
    "        return [\n",
    "            {\"role\": \"system\", \"content\": base},\n",
    "            {\"role\": \"user\",   \"content\": prepped}\n",
    "        ]\n",
    "\n",
    "    def build_prompts(self, prepped:str)->Dict[str,List[Dict[str, Any]]: \n",
    "        self._get_game_contex()\n",
    "        prompts = []\n",
    "\n",
    "        # TODO: Make sure \"langauges\" is appropriately passed here\n",
    "        for lang in self.languages:\n",
    "           prompt = self._generate_prompt_helper(lang, self.game, self.prepped)\n",
    "           prompts.append(prompt)\n",
    "        \n",
    "        self.prompts = prompts\n",
    "        self.groups = dict(zip(self.languages, prompts))\n",
    "\n",
    "        return groups\n",
    "\n",
    "    #return ->Tuple[str, Dict[str, int]]\n",
    "    def _call_model_batch(self, prompt:str):\n",
    "        \"\"\"\n",
    "        Must return (outputs, usage_dict) where usage_dict includes:\n",
    "          {'prompt_tokens': int, 'completion_tokens': int}\n",
    "        \"\"\"\n",
    "        MODEL = \"gpt-4o\"\n",
    "        temperature = 0.05\n",
    "\n",
    "        response = self.gpt_client.chat.completions.create(\n",
    "                model=MODEL, \n",
    "                messages=prompt,\n",
    "                temperature=0.05  # adjust for creativity vs. stability\n",
    "        )\n",
    "    \n",
    "        ### call GPT model for translation\n",
    "        #GPT chat completions prompt\n",
    "        #raw_results = self.gpt_model.\n",
    "\n",
    "        output = response.choices[0].message.content\n",
    "        usage = response.usage\n",
    "        return (output, usage)\n",
    "\n",
    "    \n",
    "    def _parse_model_json_block(self, output:Dict[str,Any]):\n",
    "        \"\"\"\n",
    "        Cleans and parses a JSON-like string from a model output wrapped in markdown code block.\n",
    "        \n",
    "        Args:\n",
    "            raw_output (str): The raw output string, e.g., from GPT, wrapped with ```json ... ```\n",
    "        \n",
    "        Returns:\n",
    "            list[dict]: Parsed JSON content as Python list of dictionaries.\n",
    "            \n",
    "        Raises:\n",
    "            ValueError: If the cleaned string cannot be parsed as valid JSON.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Strip markdown-style code block markers and leading/trailing whitespace\n",
    "            cleaned = re.sub(r\"^```json|```$\", \"\", raw_output.strip(), flags=re.IGNORECASE).strip()\n",
    "\n",
    "            # Replace escaped newlines (if necessary) and extra leading/trailing junk\n",
    "            cleaned = cleaned.replace(\"\\\\n\", \"\").replace(\"\\n\", \"\").strip()\n",
    "\n",
    "            # Now parse\n",
    "            loaded = json.loads(cleaned)\n",
    "        except json.JSONDecodeError as e:\n",
    "            raise ValueError(f\"Could not parse JSON: {e}\")\n",
    "\n",
    "        if isinstance(loaded, str):\n",
    "            try:\n",
    "                return json.loads(loaded)\n",
    "            except:\n",
    "                raise ValueError(f\"Could not parse JSON: {e}\")\n",
    "        else:\n",
    "            return loaded\n",
    "\n",
    "\n",
    "    def postprocess(self, \n",
    "                    outputs): \n",
    "        \n",
    "        postprocessed_dfs = []\n",
    "        for output in outputs:\n",
    "            parsed = self._parse_model_json_block(output)\n",
    "            returned_df = pd.DataFrame(parsed)\n",
    "            postprocessed_dfs.append(returned_df)\n",
    "\n",
    "        self.postprocessed_dfs = postprocessed_dfs \n",
    "\n",
    "        return self.postprocessed_dfs\n",
    "\n",
    "    def _merge_outputs_by_language(self, \n",
    "                                   post: List[pd.DataFrame]):\n",
    "        \n",
    "        for i in post:\n",
    "            self.df = self.df.merge(i, on=['token'],how='left')\n",
    "        \n",
    "        return self.df \n",
    "\n",
    "    def write_outputs(self, post:List[pd.DataFrame]): \n",
    "\n",
    "        results = self._merge_outputs_by_language(post)\n",
    "\n",
    "        #TODO: May want to update this later so I'm not removing superfluous context - more about the formatting of the template\n",
    "        results.drop(columns=['context'])\n",
    "        \n",
    "        wksht = self.sh.worksheet(\"output\")\n",
    "\n",
    "        out_data = results.values.tolist()\n",
    "        data_range = f\"A2:Q{len(out_data)+1}\"\n",
    "\n",
    "        wksht.batch_update([{'range':data_range, 'values':out_data}])\n",
    "\n",
    "        return \"Done!\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5b567e95-17e7-4866-bde9-7f4cd48c34fd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "LocalizerClass.py",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
